{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does the land use of a province (in the Netherlands) affect the number of people who die from a certain disease?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer the above question, the following datasets were used: <br>\n",
    "* https://opendata.cbs.nl/statline/portal.html?_la=nl&_catalog=CBS&tableId=70262ned&_theme=298\n",
    "* https://opendata.cbs.nl/statline/portal.html?_la=nl&_catalog=CBS&tableId=80142ned&_theme=289\n",
    "* https://opendata.cbs.nl/statline/portal.html?_la=nl&_catalog=CBS&tableId=37259ned&_theme=257\n",
    "* https://www.webuildinternet.com/articles/2015-07-19-geojson-data-of-the-netherlands/provinces.geojson\n",
    "\n",
    "During the first analysis, all columns for causes of death and a selected number of columns for land use were included. <br>\n",
    "Later a smaller selection was made by focusing on Diseases of the Respiratory System (causes of death) and the following columns of land use: Total Traffic Area, Total Built Area, Total Recreation area, Total Agricultural Site and Total Forest And Open Natural Terrain.<br>\n",
    "The last plots were only created between Diseases of the Respiratory System and Total Forest And Open Natural Terrain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml #config file\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bokeh.models import ColumnDataSource, HoverTool, Legend, LegendItem, Title, Span, FactorRange\n",
    "from bokeh.models import (BasicTicker, ColorBar, ColumnDataSource,\n",
    "                          LinearColorMapper, PrintfTickFormatter,)\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.transform import dodge, factor_cmap, factor_mark, transform\n",
    "from bokeh.palettes import Set3, Category20, Viridis256, Plasma256\n",
    "from bokeh.models.widgets import Panel, Tabs\n",
    "from bokeh.layouts import row\n",
    "\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import iqr, mannwhitneyu, norm  # iqr is the Interquartile Range function\n",
    "import seaborn as sns\n",
    "\n",
    "import doctest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data\n",
    "The data is read by using a config file, which contains all paths of the used files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config():\n",
    "    '''\n",
    "    Reads the config file\n",
    "    \n",
    "    return:\n",
    "        config: A dictionary with the paths of different files.\n",
    "    '''\n",
    "    with open(\"config.yaml\", 'r') as con:\n",
    "        config = yaml.safe_load(con)\n",
    "    return config\n",
    "\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "#https://opendata.cbs.nl/statline/portal.html?_la=nl&_catalog=CBS&tableId=70262ned&_theme=298\n",
    "df_landuse = pd.read_csv(config['path_land_use'], sep=';', engine='python')\n",
    "#https://opendata.cbs.nl/statline/portal.html?_la=nl&_catalog=CBS&tableId=80142ned&_theme=289\n",
    "df_deceased = pd.read_csv(config['path_deceased'], sep=';', engine='python')\n",
    "#https://opendata.cbs.nl/statline/portal.html?_la=nl&_catalog=CBS&tableId=37259ned&_theme=257\n",
    "df_population_development = pd.read_csv(config['path_population_development'], sep=';', engine='python')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filteren Data\n",
    "The data is filtered.\n",
    "* columns are selected or dropped\n",
    "* only the rows of provinces are selected\n",
    "* Percentages are calculated\n",
    "    * deceased persons compared to persons on December 31 of that year in die provincie\n",
    "    * land use in relation to the total area of that province in that year\n",
    "* Data frames are merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_percentage(pv_df, number_col, div_col):\n",
    "    '''    \n",
    "    This function calculates the percentages with respect to the div_col\n",
    "    \n",
    "    parameters:\n",
    "         pv_df:         The dataframe with the data.\n",
    "         number_col:    The column number from which the percentage should be calculated.\n",
    "         div_col:       The column name of the column to divide by.\n",
    "    \n",
    "    return:\n",
    "         percentage_df: Returns a data frame with percentages relative to div_col\n",
    "    \n",
    "    \n",
    "    Doctest:\n",
    "    >>> cal_percentage(pd.DataFrame({\"test1\": [1 ,4, 4, 8, 6, 110, -60], \"test2\": [2 ,2, 8, 24, 3, 440, -90]}), 1, 'test1')\n",
    "       test1  test2_percentage\n",
    "    0      1             200.0\n",
    "    1      4              50.0\n",
    "    2      4             200.0\n",
    "    3      8             300.0\n",
    "    4      6              50.0\n",
    "    5    110             400.0\n",
    "    6    -60             150.0\n",
    "    \n",
    "     '''\n",
    "    columns_df = list(pv_df.columns)[number_col:]\n",
    "    percentage_df = pv_df[pv_df.columns[:number_col]].copy()\n",
    "    for name in columns_df:\n",
    "        new_col_name = name + '_percentage'\n",
    "        percentage_df[new_col_name] = (pv_df[name]/pv_df[div_col])* 100\n",
    "    return percentage_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(df, name_cols, percentage, drop, **values_perc):\n",
    "    '''\n",
    "     Columns are selected or dropped.\n",
    "     The rows containing '(PV)' are selected, these rows contain provinces.\n",
    "     Optionally, the cal_percentage () function is called.\n",
    "    \n",
    "     parameters:\n",
    "         df:              The data frame containing the data.\n",
    "         name_cols:       The column names to be selected or deleted.\n",
    "         percentage:      True or False. The percentage must be calculated.\n",
    "         drop:            True, if columns are to be removed. False, if there are columns to be selected.\n",
    "         ** values_perc:  When percentage == True, two extra values are included:\n",
    "                                             number_col: The column number from which the percentage should be calculated.\n",
    "                                             div_col:    The column name of the column to divide by.\n",
    "        \n",
    "     return:\n",
    "         pv_df:           Returns the filtered data frame (with possibly already percentages).\n",
    "         \n",
    "         \n",
    "    Doctest:\n",
    "    >>> filter_data(pd.DataFrame({\"RegioS\": ['Groningen (PV)' ,'Groingen', 'Test (pv)', 'Test (PV)'], \"Perioden\": [2002 ,2020, 2008, 2004], \"test\": [2 ,2, 8, 24]}), ['test'], False, True)\n",
    "               RegioS  Perioden\n",
    "    0  Groningen (PV)      2002\n",
    "    3       Test (PV)      2004\n",
    "\n",
    "    \n",
    "     '''\n",
    "    # Delete or select columns\n",
    "    if drop == False:\n",
    "        select_df = df[name_cols]\n",
    "    else:\n",
    "        select_df = df.drop(name_cols, axis = 1)\n",
    "        \n",
    "    # Filter on the Regions column. Now we want all rows of provinces.\n",
    "    pv_df = select_df[select_df['RegioS'].str.contains('\\(PV\\)')]\n",
    "    \n",
    "    # Checks whether the percentage should be calculated or not.\n",
    "    if percentage == True:\n",
    "        pv_df = cal_percentage(pv_df, values_perc['number_col'], values_perc['div_col'])\n",
    "        \n",
    "    return pv_df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Land use data is filtered\n",
    "# The selected column names\n",
    "land_name_cols = ['ID', 'RegioS', 'Perioden', 'TotaleOppervlakte_1', 'TotaalVerkeersterrein_2',\n",
    "                  'TotaalBebouwdTerrein_6', 'Woonterrein_7', 'TotaalRecreatieterrein_19', 'ParkEnPlantsoen_20', 'Sportterrein_21',\n",
    "                  'TotaalAgrarischTerrein_25', 'TotaalBosEnOpenNatuurlijkTerrein_28', 'Bos_29', 'OpenDroogNatuurlijkTerrein_30', \n",
    "                   'OpenNatNatuurlijkTerrein_31']\n",
    "percentage_landuse = filter_data(df_landuse, land_name_cols, True, False, number_col=4, div_col = 'TotaleOppervlakte_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population development data is filtered\n",
    "# Filter on 'Men and Women'\n",
    "select_population_development = df_population_development[df_population_development['Geslacht'] == 'Mannen en vrouwen']\n",
    "# The selected column names\n",
    "population_name_cols = ['RegioS', 'Perioden', 'BevolkingOp1Januari_1', 'BevolkingOp31December_20', 'Overledenen_5']\n",
    "pv_population_development = filter_data(select_population_development, population_name_cols, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deceased data is filtered\n",
    "# The columns to be dropped.\n",
    "deceased_name_cols = ['Unnamed: 0', 'ID']\n",
    "# This filtering was done after I saw that something was wrong within Check Data\n",
    "# When this check is now performed in Check Data, it is correct.\n",
    "df_deceased['RegioS'] = df_deceased['RegioS'].replace('FryslÃ¢n (PV)', 'Friesland (PV)')\n",
    "pv_deceased = filter_data(df_deceased, deceased_name_cols, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data frames pv_deceased and pv_population_development are merged\n",
    "pv_population_deceased = pd.DataFrame(pd.merge(pv_population_development, pv_deceased, on = ['RegioS','Perioden'])).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to normalize by taking the percentage relative to Population on December 31.\n",
    "I was very doubtful whether this should not be done on the Population on January 1. Because the people who died were still alive then.\n",
    "But in the end I chose to normalize to the Population on December 31.\n",
    "This is because only the survivor is not counted, but people who have moved to the prophet or people who have just moved out of the prophesy.\n",
    "Also, if you put everything through the same column, it should not ultimately yield completely different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentages relative to PopulationOn31December\n",
    "percentage_deceased = cal_percentage(pv_population_deceased, 6, 'BevolkingOp31December_20')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge the Dataframes into 1 large dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data frames percentage_deceased and percentage_landuse are merged\n",
    "pv_deceased_landuse_perc = pd.DataFrame(pd.merge(percentage_deceased, percentage_landuse, on = ['RegioS','Perioden'])).reset_index()\n",
    "# Drop columns\n",
    "pv_deceased_landuse_perc = pv_deceased_landuse_perc.drop(['level_0', 'index','ID',], axis=1)\n",
    "pv_deceased_landuse_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check data\n",
    "* Check Datatypes\n",
    "* Missing values\n",
    "* Make sure that every province has the same years\n",
    "\n",
    "This is not written in functions, as it consists of only a few lines. These outcomes are easy to see by jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the datatypes of the dataframe\n",
    "pv_deceased_landuse_perc.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data types are good in my opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing data\n",
    "percent_missing = pv_deceased_landuse_perc.isnull().sum() * 100 / len(pv_deceased_landuse_perc)\n",
    "percent_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the years all occur 12 times (NL has 12 provinces).\n",
    "df_dict = dict()\n",
    "for i in pv_deceased_landuse_perc.columns:\n",
    "    counts = pv_deceased_landuse_perc[i].value_counts().to_dict()\n",
    "    df_dict[i] = counts\n",
    "    \n",
    "df_dict['Perioden']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The years all occurred 11 times.\n",
    "To check this, it is checked how many provinces are present in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many provinces there are\n",
    "all_provinces = set(pv_deceased_landuse_perc['RegioS'])\n",
    "print(len(all_provinces))\n",
    "print(all_provinces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the data was checked, it can be seen that Friesland is missing, this is because it is written differently in the deceased_df, namely: 'FryslÃ¢n (PV)' instead of 'Friesland (PV)'. This discovery has been adapted above. This is therefore no longer visible when this code is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An overview of pv_deceased_landuse_perc\n",
    "pv_deceased_landuse_perc.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some plots\n",
    "* figure 1-4:   Stacked and grouped barplot\n",
    "* figure 5:     Heatmap\n",
    "* figure 6-8:   Boxplots\n",
    "* figure 9:     QQ-plots\n",
    "* figure 10-11: Histogram (normal distribution)\n",
    "* figure 12-15: Scatterplot\n",
    "* figure 16:    Map\n",
    "* figure 17-20: OLS\n",
    "  * consists of: Result summary, seaborn OLS, bokeh OLS\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Data used for the plots\n",
    "* figure 1-10: all columns for causes of death and a selected number of columns for land use were included\n",
    "* figure 11-17: a smaller selection was made by focusing on Diseases of the Respiratory System (causes of death) and the following columns of land use: Total Traffic Area, Total Built Area, Total Recreation area, Total Agricultural Site and Total Forest And Open Natural Terrain.\n",
    "* figure 18-20:only created between Diseases of the Respiratory System and Total Forest And Open Natural Terrain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the categorys\n",
    "cat_all = ['TotaalVerkeersterrein_2_percentage',\n",
    "              'TotaalBebouwdTerrein_6_percentage', 'Woonterrein_7_percentage', 'TotaalRecreatieterrein_19_percentage', 'ParkEnPlantsoen_20_percentage', 'Sportterrein_21_percentage',\n",
    "              'TotaalAgrarischTerrein_25_percentage', 'TotaalBosEnOpenNatuurlijkTerrein_28_percentage', 'Bos_29_percentage', 'OpenDroogNatuurlijkTerrein_30_percentage', \n",
    "               'OpenNatNatuurlijkTerrein_31_percentage',\n",
    "              'TotaalAlleOnderliggendeDoodsoorzaken_1_percentage', 'Nieuwvormingen_2_percentage', 'ZiektenVanHartEnVaatstelsel_3_percentage', 'ZiektenVanAdemhalingsstelsel_4_percentage', 'UitwendigeDoodsoorzaken_5_percentage', 'OverigeDoodsoorzaken_6_percentage']\n",
    "cat_land = ['TotaalVerkeersterrein_2_percentage',\n",
    "              'TotaalBebouwdTerrein_6_percentage', 'Woonterrein_7_percentage', 'TotaalRecreatieterrein_19_percentage', 'ParkEnPlantsoen_20_percentage', 'Sportterrein_21_percentage',\n",
    "              'TotaalAgrarischTerrein_25_percentage', 'TotaalBosEnOpenNatuurlijkTerrein_28_percentage', 'Bos_29_percentage', 'OpenDroogNatuurlijkTerrein_30_percentage', \n",
    "               'OpenNatNatuurlijkTerrein_31_percentage']\n",
    "cat_deceased = ['TotaalAlleOnderliggendeDoodsoorzaken_1_percentage', 'Nieuwvormingen_2_percentage', 'ZiektenVanHartEnVaatstelsel_3_percentage', 'ZiektenVanAdemhalingsstelsel_4_percentage', 'UitwendigeDoodsoorzaken_5_percentage', 'OverigeDoodsoorzaken_6_percentage']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked and grouped barplot\n",
    "* figure 1: Percentage of various underlying causes of death per province per year\n",
    "* figure 2: Percentage of various underlying causes of death per year by province\n",
    "* figure 3: Percentage of land use per province per year\n",
    "* figure 4: Percentage of land use per year per province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_stack_group(df, groups, color, region_per):\n",
    "    '''\n",
    "    Creates the data so that a stacked grouped plot can be easily created.\n",
    "    \n",
    "    parameters:\n",
    "        df:          The dataframe with the data.\n",
    "        groups:      The group (colums) of deceased / land use / all, for which the data is prepared\n",
    "        color:       The color palette used in the stacked and grouped bar plot\n",
    "        region_per:  True: if RegioS Perioden, False if Perioden RegioS\n",
    "    \n",
    "    return:\n",
    "        factors:     A list with tuples with all unique RegionS and Perioden combined\n",
    "        data:        A dict with keys: x (value: factors) and all groups (value: a list of their values)\n",
    "        col_pallet:  A tuple with the color palette\n",
    "        \n",
    "    \n",
    "        \n",
    "    Doctest:\n",
    "    >>> make_data_stack_group(pd.DataFrame({\"RegioS\": ['Groningen (PV)' ,'Groingen (PV)', 'Gelderland (pv)', 'Gelderland (PV)'], \"Perioden\": [2002 ,2020, 2008, 2004], \"a\": [2 ,2, 8, 24], \"b\": [1,2,3,4], \"c\": [5,6,7,8], \"d\": [5,6,7,8]}), ['a', 'b', 'c'], Set3, True)\n",
    "    ([('Groningen (PV)', '2002'), ('Groingen (PV)', '2020'), ('Gelderland (pv)', '2008'), ('Gelderland (PV)', '2004')], {'x': [('Groningen (PV)', '2002'), ('Groingen (PV)', '2020'), ('Gelderland (pv)', '2008'), ('Gelderland (PV)', '2004')], 'a': [2, 2, 8, 24], 'b': [1, 2, 3, 4], 'c': [5, 6, 7, 8]}, ('#8dd3c7', '#ffffb3', '#bebada'))\n",
    "    '''\n",
    "    data = {}\n",
    "    factors = []\n",
    "    for index, row in df.iterrows():\n",
    "        if region_per == True:\n",
    "            factors.append((row['RegioS'], str(row['Perioden'])))\n",
    "        else:\n",
    "            factors.append((str(row['Perioden']), row['RegioS']))\n",
    "    data['x'] = factors\n",
    "    for name in groups:\n",
    "        data[f'{name}'] = list(df[name])\n",
    "    return factors, data, color[len(groups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_and_grouped_bar(source, groups, factors, color, width, height, title, label, sub_title):\n",
    "    '''\n",
    "    Creates the stacked grouped bar plot\n",
    "    \n",
    "    parameters:\n",
    "        source:     The source (dataframe, data) of which the plot is to be made.\n",
    "        groups:     The group (colums) of deceased / land use / all, for which the data is prepared\n",
    "        factors:    A list with tuples with all unique RegionS and Perioden combined\n",
    "        color:      A tuple with the color palette\n",
    "        width:      The width of the plot\n",
    "        height:     The Hight of the plot\n",
    "        title:      The title of the plot\n",
    "        label:      The label for the Hover\n",
    "        sub_title:  The sub title of the plot\n",
    "        \n",
    "    return:\n",
    "        p:          The stacked and grouped bar plot    \n",
    "    '''\n",
    "    p = figure(x_range=FactorRange(*factors), plot_height=height, plot_width=width,\n",
    "           toolbar_location=None, tools=\"\", x_axis_label = 'Year and province', y_axis_label='Percentage')\n",
    "    p.add_layout(Title(text=sub_title, text_font_size=\"8pt\", text_font_style=\"italic\"), 'above')\n",
    "    p.add_layout(Title(text=title, text_font_size=\"10pt\"), 'above')\n",
    "        \n",
    "    p.vbar_stack(groups, x='x', width=0.8, alpha=0.8, color=color, source=source,\n",
    "                 legend_label=[x.split('_')[0] for x in groups])\n",
    "    \n",
    "    p.x_range.range_padding = 0.01\n",
    "    p.xaxis.major_label_orientation = 1\n",
    "    p.xgrid.grid_line_color = None\n",
    "\n",
    "    # Legend\n",
    "    new_legend = p.legend[0]\n",
    "    p.add_layout(new_legend, 'right') \n",
    "    p.legend.orientation = \"vertical\" \n",
    "    p.xaxis.major_label_orientation = \"vertical\"\n",
    "    \n",
    "    # Hover\n",
    "    tips = [\n",
    "        (label, f\"@x\")\n",
    "    ]\n",
    "    for name in groups:\n",
    "        new_name = name.split('_')[0]\n",
    "        tips.append( (new_name, f'@{name} %') )\n",
    "        \n",
    "    p.add_tools(HoverTool( tooltips = tips\n",
    "                            ))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 1: Percentage of various underlying causes of death per province per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked grouped bar plot for: region periods, deceased\n",
    "factors_deceased_region, data_deceased_region, color_pal_deceased_region = make_data_stack_group(pv_deceased_landuse_perc, cat_deceased, Set3, True)\n",
    "source_bar_deceased_region = ColumnDataSource(data=data_deceased_region)\n",
    "stacked_grouped_deceased_reg_per = stacked_and_grouped_bar(source_bar_deceased_region, cat_deceased, factors_deceased_region, color_pal_deceased_region, 1500, 250,\n",
    "                            'Percentage of various underlying causes of death per province per year', \"Province-year\", 'Percentage compared to the total number of inhabitants in that province')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(stacked_grouped_deceased_reg_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2: Percentage of various underlying causes of death per year by province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked grouped bar plot for: periods Region, deceased\n",
    "factors_deceased_per, data_deceased_per, color_pal_deceased_per = make_data_stack_group(pv_deceased_landuse_perc, cat_deceased, Set3, False)\n",
    "source_bar_deceased_per = ColumnDataSource(data=data_deceased_per)\n",
    "stacked_grouped_deceased_per_reg = stacked_and_grouped_bar(source_bar_deceased_per, cat_deceased, factors_deceased_per, color_pal_deceased_per, 2500, 400,\n",
    "                            'Percentage of various underlying causes of death per year by province', \"Year-province\", 'Percentage compared to the total number of inhabitants in that province')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(stacked_grouped_deceased_per_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3: Percentage of land use per province per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked grouped bar plot for: Region periods, land\n",
    "factors_land_region, data_land_region, color_pal_land_region = make_data_stack_group(pv_deceased_landuse_perc, cat_land, Set3, True)\n",
    "source_bar_land_region = ColumnDataSource(data=data_land_region)\n",
    "stacked_grouped_land_reg_per = stacked_and_grouped_bar(source_bar_land_region, cat_land, factors_land_region, color_pal_land_region, 2500, 500,\n",
    "                            'Percentage of land use per province per year', \"Province-year\", 'Percentage in relation to the total area of that province')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(stacked_grouped_land_reg_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4: Percentage of land use per year per province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacked grouped bar plot for: periods region, land\n",
    "factors_land_per, data_land_per, color_pal_land_per = make_data_stack_group(pv_deceased_landuse_perc, cat_land, Set3, False)\n",
    "source_bar_land_per = ColumnDataSource(data=data_land_per)\n",
    "stacked_grouped_land_per_reg = stacked_and_grouped_bar(source_bar_land_per, cat_land, factors_land_per, color_pal_land_per, 2500, 500,\n",
    "                            'Percentage of land use per year per province',\"Year-province\", 'Percentage in relation to the total area of that province')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(stacked_grouped_land_per_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap\n",
    "* Figure 5: Correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(df, palette):\n",
    "    '''\n",
    "    Creates a heat map of the supplied data\n",
    "    \n",
    "    parameters:\n",
    "        df:       The dataframe with the data.\n",
    "        palette:  The color used to create the heat map\n",
    "    \n",
    "    return:\n",
    "        p:        The Heatmap\n",
    "    '''\n",
    "    cor = df.corr().abs()\n",
    "    y_range = (list(reversed(cor.columns)))\n",
    "    x_range = (list(cor.index))\n",
    "\n",
    "    dfc = pd.DataFrame(cor.stack(), columns=['r']).reset_index()\n",
    "    source = ColumnDataSource(dfc)   \n",
    "\n",
    "    #create colormapper \n",
    "    mapper = LinearColorMapper(palette=Viridis256, low=dfc.r.min(), high=dfc.r.max())\n",
    "    #create plot\n",
    "    p = figure(title=\"Correlation heatmap\", plot_width=800, plot_height=800,\n",
    "               x_range=x_range, y_range=y_range, x_axis_location=\"above\", toolbar_location=None)\n",
    "    #use mapper to fill the rectangles in the plot\n",
    "    p.rect(x=\"level_0\", y=\"level_1\", width=1, height=1, source=source,\n",
    "           line_color=None, fill_color=transform('r', mapper))\n",
    "    #create and add colorbar to the right\n",
    "    color_bar = ColorBar(color_mapper=mapper, location=(0, 0),\n",
    "                         ticker=BasicTicker(desired_num_ticks=len(x_range)), \n",
    "                         formatter=PrintfTickFormatter(format=\"%.1f\"))\n",
    "    p.add_layout(color_bar, 'right')\n",
    "\n",
    "    #draw axis\n",
    "    p.axis.axis_line_color = None\n",
    "    p.axis.major_tick_line_color = None\n",
    "    p.axis.major_label_text_font_size = \"10px\"\n",
    "    p.axis.major_label_standoff = 0\n",
    "    p.xaxis.major_label_orientation = 1.0\n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 5: Correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a heat map of the supplied data\n",
    "heatmap_pv_deceased_landuse_perc = heatmap(pv_deceased_landuse_perc, Plasma256)\n",
    "show(heatmap_pv_deceased_landuse_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxplot\n",
    "* figure 6: Box plot by Perioden for ...\n",
    "* figure 7: Box plot by RegioS for ...\n",
    "* figure 8: Box plot by RegioS-Perioden for ...\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "These plots are in tabs.\n",
    "Each tab contains a different column on the y axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_fun(df, value, by): \n",
    "    '''\n",
    "    Makes a box plot of the supplied data\n",
    "    \n",
    "    parameters:\n",
    "        df:    The dataframe with the data.\n",
    "        value: Column name. This data is used for the y-axis\n",
    "        by:    Value on which the box plot should be made (x-axis)\n",
    "    \n",
    "    return:\n",
    "        p:     The Boxplot\n",
    "    '''\n",
    "    \n",
    "    if isinstance(by, str):\n",
    "        label = by\n",
    "        df[by] = df[by].astype(str).copy()\n",
    "        df[[by, value]].copy()\n",
    "        cats = sorted(df[by].unique())\n",
    "        groups = df.groupby(by)\n",
    "    else:\n",
    "        label = by[0]+'-'+by[1]\n",
    "        df[[by[0], by[1], value]].copy()\n",
    "        df['group'] = df[by[0]].astype(str) + \"-\" + df[by[1]].astype(str)\n",
    "        cats = sorted(df['group'].unique())\n",
    "        groups = df.groupby('group')\n",
    "\n",
    "    q1 = groups.quantile(q=0.25)\n",
    "    q2 = groups.quantile(q=0.5)\n",
    "    q3 = groups.quantile(q=0.75)\n",
    "    iqr = q3 - q1\n",
    "    upper = q3 + 1.5*iqr\n",
    "    lower = q1 - 1.5*iqr\n",
    "\n",
    "    # find the outliers for each category\n",
    "    def outliers(group):\n",
    "        cat = group.name\n",
    "        return group[(group[value] > upper.loc[cat][value]) | (group[value] < lower.loc[cat][value])][value]\n",
    "    out = groups.apply(outliers).dropna()\n",
    "\n",
    "    # prepare outlier data for plotting, we need coordinates for every outlier.\n",
    "    if not out.empty:\n",
    "        outx = []\n",
    "        outy = []\n",
    "        for keys in out.index:\n",
    "            outx.append(keys[0])\n",
    "            outy.append(out.loc[keys[0]].loc[keys[1]])\n",
    "\n",
    "    p = figure(tools=\"\", background_fill_color=\"#efefef\", x_range=cats, toolbar_location=None,\n",
    "              y_axis_label=f'{value.split(\"_\")[0]} percentage', x_axis_label=label)\n",
    "    p.add_layout(Title(text=f'Box plot by {label} for {value.split(\"_\")[0]}', text_font_size=\"10pt\"), 'above')\n",
    "   \n",
    "    # if no outliers, shrink lengths of stems to be no longer than the minimums or maximums\n",
    "    qmin = groups.quantile(q=0.00)\n",
    "    qmax = groups.quantile(q=1.00)\n",
    "    upper[value] = [min([x,y]) for (x,y) in zip(list(qmax.loc[:,value]),upper[value])]\n",
    "    lower[value] = [max([x,y]) for (x,y) in zip(list(qmin.loc[:,value]),lower[value])]\n",
    "\n",
    "    # stems\n",
    "    p.segment(cats, upper[value], cats, q3[value], line_color=\"black\")\n",
    "    p.segment(cats, lower[value], cats, q1[value], line_color=\"black\")\n",
    "    \n",
    "    # boxes\n",
    "    p.vbar(cats, 0.7, q2[value], q3[value], fill_color=\"skyblue\", line_color=\"black\")\n",
    "    p.vbar(cats, 0.7, q1[value], q2[value], fill_color=\"skyblue\", line_color=\"black\")\n",
    "    \n",
    "    different = max(upper[value]) - min(lower[value])\n",
    "    if different > 5:\n",
    "        height = 0.006\n",
    "    elif different > 1.0:\n",
    "        height = 0.001\n",
    "    elif different > 0.05:\n",
    "        height = 0.00001\n",
    "    else:\n",
    "        height = 0.000005\n",
    "    # whiskers (almost-0 height rects simpler than segments)\n",
    "    p.rect(cats, lower[value], 0.2, height, line_color=\"black\")\n",
    "    p.rect(cats, upper[value], 0.2, height, line_color=\"black\")\n",
    "\n",
    "    # outliers\n",
    "    if not out.empty:\n",
    "        p.circle(outx, outy, size=6, color=\"deeppink\", fill_alpha=0.6)\n",
    "\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.ygrid.grid_line_color = \"white\"\n",
    "    p.grid.grid_line_width = 2\n",
    "    p.xaxis.major_label_text_font_size=\"10px\"\n",
    "    p.xaxis.major_label_orientation = \"vertical\"\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_box(df, category, col):\n",
    "    '''\n",
    "    Put all box plots in panels and tabs\n",
    "    \n",
    "    parameters:\n",
    "        df:       The dataframe with the data.\n",
    "        category: Column names.\n",
    "        col:      Value on which the box plot should be made (x-axis)\n",
    "    \n",
    "    return:\n",
    "        box_all:  Tabs with Panels with the boxplots\n",
    "    '''\n",
    "    tabs = []\n",
    "    for cat in category:\n",
    "        box = boxplot_fun(df, cat, col)\n",
    "        tabs.append(Panel(child=box, title=str(cat.split('_')[0])))\n",
    "    box_all = Tabs(tabs=tabs)\n",
    "    return box_all\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure 6: Box plot by Perioden for ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_per = data_box(pv_deceased_landuse_perc, cat_all, 'Perioden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(box_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure 7: Box plot by RegioS for ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_region = data_box(pv_deceased_landuse_perc, cat_all, 'RegioS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(box_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure 8: Box plot by RegioS-Perioden for ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_region_per = data_box(pv_deceased_landuse_perc, cat_all, ['RegioS', 'Perioden'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(box_region_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal distribution (QQ-plot / Histogram)\n",
    "* figure 9:  Q-Q plot (ML) - ....      and   Q-Q plot (robust) - ....\n",
    "* figure 10: Histogram: ..... (For RegioS)\n",
    "* figure 11: Histogram: ..... (For Perioden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_qq_and_histogram(y, histogram):\n",
    "    \"\"\"\n",
    "    Calculations are performed and returned for the qq plots and histograms\n",
    "    \n",
    "    parameters:\n",
    "        y:         Dates on which the calculations are performed. (list)       \n",
    "        histogram: True-> histogram, False-> QQ-plots\n",
    "    \n",
    "    returns:\n",
    "        Both:\n",
    "            mu:       mu (mean) of y\n",
    "            sigma2:   variance\n",
    "            sigma:    standard deviation\n",
    "        histogram == True:\n",
    "            x:        evenly spaced numbers over a specified interval.\n",
    "            rv:       a list. norm.pdf has been executed over the list x.\n",
    "        histogram == False:\n",
    "            s2:      unbiased variance\n",
    "            s:       unbiased standard deviation\n",
    "            mu_R:    Robust (mean)\n",
    "            sigma_R: Robust standard deviation\n",
    "            n:       length of list y\n",
    "    \n",
    "    \n",
    "    Doctest:\n",
    "    >>> cal_qq_and_histogram([1, 20, 34, 56, 3, 8, 99], True)\n",
    "    (31.571428571428573, 1084.2448979591838, 32.92787417916899, array([  0.75 ,   1.365,   1.98 ,   2.595,   3.21 ,   3.825,   4.44 ,\n",
    "             5.055,   5.67 ,   6.285,   6.9  ,   7.515,   8.13 ,   8.745,\n",
    "             9.36 ,   9.975,  10.59 ,  11.205,  11.82 ,  12.435,  13.05 ,\n",
    "            13.665,  14.28 ,  14.895,  15.51 ,  16.125,  16.74 ,  17.355,\n",
    "            17.97 ,  18.585,  19.2  ,  19.815,  20.43 ,  21.045,  21.66 ,\n",
    "            22.275,  22.89 ,  23.505,  24.12 ,  24.735,  25.35 ,  25.965,\n",
    "            26.58 ,  27.195,  27.81 ,  28.425,  29.04 ,  29.655,  30.27 ,\n",
    "            30.885,  31.5  ,  32.115,  32.73 ,  33.345,  33.96 ,  34.575,\n",
    "            35.19 ,  35.805,  36.42 ,  37.035,  37.65 ,  38.265,  38.88 ,\n",
    "            39.495,  40.11 ,  40.725,  41.34 ,  41.955,  42.57 ,  43.185,\n",
    "            43.8  ,  44.415,  45.03 ,  45.645,  46.26 ,  46.875,  47.49 ,\n",
    "            48.105,  48.72 ,  49.335,  49.95 ,  50.565,  51.18 ,  51.795,\n",
    "            52.41 ,  53.025,  53.64 ,  54.255,  54.87 ,  55.485,  56.1  ,\n",
    "            56.715,  57.33 ,  57.945,  58.56 ,  59.175,  59.79 ,  60.405,\n",
    "            61.02 ,  61.635,  62.25 ,  62.865,  63.48 ,  64.095,  64.71 ,\n",
    "            65.325,  65.94 ,  66.555,  67.17 ,  67.785,  68.4  ,  69.015,\n",
    "            69.63 ,  70.245,  70.86 ,  71.475,  72.09 ,  72.705,  73.32 ,\n",
    "            73.935,  74.55 ,  75.165,  75.78 ,  76.395,  77.01 ,  77.625,\n",
    "            78.24 ,  78.855,  79.47 ,  80.085,  80.7  ,  81.315,  81.93 ,\n",
    "            82.545,  83.16 ,  83.775,  84.39 ,  85.005,  85.62 ,  86.235,\n",
    "            86.85 ,  87.465,  88.08 ,  88.695,  89.31 ,  89.925,  90.54 ,\n",
    "            91.155,  91.77 ,  92.385,  93.   ,  93.615,  94.23 ,  94.845,\n",
    "            95.46 ,  96.075,  96.69 ,  97.305,  97.92 ,  98.535,  99.15 ,\n",
    "            99.765, 100.38 , 100.995, 101.61 , 102.225, 102.84 , 103.455,\n",
    "           104.07 , 104.685, 105.3  , 105.915, 106.53 , 107.145, 107.76 ,\n",
    "           108.375, 108.99 , 109.605, 110.22 , 110.835, 111.45 , 112.065,\n",
    "           112.68 , 113.295, 113.91 , 114.525, 115.14 , 115.755, 116.37 ,\n",
    "           116.985, 117.6  , 118.215, 118.83 , 119.445, 120.06 , 120.675,\n",
    "           121.29 , 121.905, 122.52 , 123.135, 123.75 ]), array([0.00781795, 0.00795444, 0.00809049, 0.008226  , 0.00836086,\n",
    "           0.00849497, 0.00862822, 0.0087605 , 0.0088917 , 0.00902173,\n",
    "           0.00915046, 0.0092778 , 0.00940362, 0.00952783, 0.00965031,\n",
    "           0.00977095, 0.00988966, 0.01000631, 0.01012081, 0.01023305,\n",
    "           0.01034292, 0.01045033, 0.01055517, 0.01065735, 0.01075676,\n",
    "           0.01085331, 0.01094691, 0.01103747, 0.01112489, 0.01120909,\n",
    "           0.01129   , 0.01136752, 0.01144158, 0.01151211, 0.01157903,\n",
    "           0.01164228, 0.01170179, 0.0117575 , 0.01180936, 0.01185731,\n",
    "           0.0119013 , 0.01194129, 0.01197724, 0.0120091 , 0.01203685,\n",
    "           0.01206045, 0.01207989, 0.01209514, 0.01210618, 0.01211301,\n",
    "           0.01211561, 0.01211399, 0.01210814, 0.01209808, 0.01208381,\n",
    "           0.01206534, 0.0120427 , 0.01201591, 0.011985  , 0.01195   ,\n",
    "           0.01191095, 0.01186788, 0.01182085, 0.01176989, 0.01171507,\n",
    "           0.01165644, 0.01159405, 0.01152797, 0.01145828, 0.01138503,\n",
    "           0.01130831, 0.01122818, 0.01114474, 0.01105806, 0.01096822,\n",
    "           0.01087532, 0.01077945, 0.01068069, 0.01057915, 0.01047492,\n",
    "           0.0103681 , 0.01025879, 0.01014709, 0.0100331 , 0.00991694,\n",
    "           0.0097987 , 0.0096785 , 0.00955644, 0.00943262, 0.00930716,\n",
    "           0.00918017, 0.00905175, 0.00892202, 0.00879107, 0.00865903,\n",
    "           0.008526  , 0.00839208, 0.00825739, 0.00812202, 0.00798609,\n",
    "           0.00784969, 0.00771293, 0.00757591, 0.00743873, 0.00730149,\n",
    "           0.00716428, 0.00702719, 0.00689032, 0.00675377, 0.00661761,\n",
    "           0.00648193, 0.00634682, 0.00621236, 0.00607863, 0.00594571,\n",
    "           0.00581366, 0.00568256, 0.00555248, 0.00542348, 0.00529564,\n",
    "           0.005169  , 0.00504364, 0.00491959, 0.00479693, 0.00467569,\n",
    "           0.00455593, 0.00443768, 0.004321  , 0.00420592, 0.00409247,\n",
    "           0.0039807 , 0.00387063, 0.00376228, 0.0036557 , 0.0035509 ,\n",
    "           0.0034479 , 0.00334671, 0.00324737, 0.00314987, 0.00305424,\n",
    "           0.00296048, 0.00286859, 0.00277859, 0.00269047, 0.00260424,\n",
    "           0.00251989, 0.00243743, 0.00235684, 0.00227812, 0.00220126,\n",
    "           0.00212625, 0.00205308, 0.00198174, 0.00191221, 0.00184448,\n",
    "           0.00177852, 0.00171433, 0.00165188, 0.00159114, 0.00153211,\n",
    "           0.00147475, 0.00141904, 0.00136496, 0.00131248, 0.00126159,\n",
    "           0.00121224, 0.00116441, 0.00111809, 0.00107323, 0.00102981,\n",
    "           0.0009878 , 0.00094718, 0.00090791, 0.00086997, 0.00083332,\n",
    "           0.00079793, 0.00076378, 0.00073084, 0.00069908, 0.00066846,\n",
    "           0.00063896, 0.00061055, 0.0005832 , 0.00055688, 0.00053156,\n",
    "           0.00050722, 0.00048382, 0.00046134, 0.00043975, 0.00041903,\n",
    "           0.00039914, 0.00038007, 0.00036178, 0.00034425, 0.00032745,\n",
    "           0.00031137, 0.00029597, 0.00028124, 0.00026714, 0.00025367,\n",
    "           0.00024079]))\n",
    "           \n",
    "    >>> cal_qq_and_histogram([1, 20, 34, 56, 3, 8, 99], False)\n",
    "    (31.571428571428573, 1084.2448979591838, 32.92787417916899, 1264.9523809523812, 35.5661690508323, 20.0, 29.28094885100074, 7)\n",
    "\n",
    " \n",
    "    \"\"\"\n",
    "    Y = np.array(y)\n",
    "    # Estimates of mu and sigma:\n",
    "    mu = np.mean(Y)\n",
    "    sigma2 = np.mean((Y- mu)**2)\n",
    "    sigma = np.sqrt(sigma2) # biased estimate\n",
    "    \n",
    "    if histogram == True:\n",
    "        # Calculate min en max for linspace\n",
    "        mini = min(y) - (min(y)*0.25)\n",
    "        maxi = max(y) + (max(y)*0.25)\n",
    "\n",
    "        x = np.linspace(mini, maxi, 201)\n",
    "        rv = np.array([norm.pdf(xi, loc = mu, scale = sigma) for xi in x])\n",
    "        return mu, sigma2, sigma, x, rv\n",
    "    else:\n",
    "        n = len(y)\n",
    "        s2 = n/(n-1) * sigma2\n",
    "        s = np.sqrt(s2) # unbiased estimate\n",
    "        # Robust estimates:\n",
    "        mu_R = np.median(y)\n",
    "        sigma_R = iqr(y)/1.349\n",
    "        return mu, sigma2, sigma, s2, s, mu_R, sigma_R, n\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q_Q_Plot(df, cat, est = 'robust', **kwargs):\n",
    "    \n",
    "    ################################################################################\n",
    "    #\n",
    "    # Arguments:\n",
    "    #\n",
    "    # y                  data array\n",
    "    # est                Estimation method for normal parameters mu and sigma:\n",
    "    #                    either 'robust' (default), or 'ML' (Maximum Likelihood),\n",
    "    #                    or 'preset' (given values)\n",
    "    # If est='preset' than the optional parameters mu, sigma must be provided\n",
    "    #\n",
    "    # Author:            M.E.F. Apol \n",
    "    # Date:              2020-01-06\n",
    "    #\n",
    "    ################################################################################\n",
    "    \"\"\"\n",
    "    Creates a QQ Plot\n",
    "    \n",
    "    parameters:\n",
    "        df:    The dataframe with the data.\n",
    "        cat:   Name of a column of which the QQ plot is to be made\n",
    "        est:   'ML'/'robust'/'preset'\n",
    "    \n",
    "    return:\n",
    "        fig:   The QQ-plot\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # First, get the optional arguments mu and sigma:\n",
    "    mu_0 = kwargs.get('mu', None)\n",
    "    sigma_0 = kwargs.get('sigma', None)\n",
    "    \n",
    "    y = df[cat]\n",
    "    \n",
    "    # Calculate order statistic:\n",
    "    y_os = np.sort(y)\n",
    "    \n",
    "    mu_ML, sigma2_ML, sigma_ML, s2, s, mu_R, sigma_R, n = cal_qq_and_histogram(y, False)\n",
    "\n",
    "    # Assign values of mu and sigma for z-transform:\n",
    "    if est == 'ML':\n",
    "        mu, sigma = mu_ML, s\n",
    "    elif est == 'robust':\n",
    "        mu, sigma = mu_R, sigma_R\n",
    "    elif est == 'preset':\n",
    "        mu, sigma = mu_0, sigma_0\n",
    "    else:\n",
    "        print('Wrong estimation method chosen!')\n",
    "        \n",
    "    # Perform z-transform: sample quantiles z.i\n",
    "    z_i = (y_os - mu)/sigma\n",
    "\n",
    "    # Calculate cumulative probabilities p.i:\n",
    "    i = np.array(range(n)) + 1\n",
    "    p_i = (i - 0.5)/n\n",
    "\n",
    "    # Calculate theoretical quantiles z.(i):\n",
    "    \n",
    "    z_th = norm.ppf(p_i, 0, 1)\n",
    "\n",
    "    # Calculate SE or theoretical quantiles:\n",
    "    SE_z_th = (1/norm.pdf(z_th, 0, 1)) * np.sqrt((p_i * (1 - p_i)) / n)\n",
    "\n",
    "    # Calculate 95% CI of diagonal line:\n",
    "    CI_upper = z_th + 1.96 * SE_z_th\n",
    "    CI_lower = z_th - 1.96 * SE_z_th\n",
    "\n",
    "    # Make Q-Q plot:\n",
    "    fig = plt.figure()\n",
    "    plt.plot(z_th, z_i, 'o', color='k', label='experimental data')\n",
    "    plt.plot(z_th, z_th, '--', color='r', label='normal line')\n",
    "    plt.plot(z_th, CI_upper, '--', color='b', label='95% CI')\n",
    "    plt.plot(z_th, CI_lower, '--', color='b')\n",
    "    plt.xlabel('Theoretical quantiles, $z_{(i)}$')\n",
    "    plt.ylabel('Sample quantiles, $z_i$')\n",
    "    plt.title(f'Q-Q plot ({est}) - {cat.split(\"_\")[0]}')\n",
    "    plt.legend(loc='best')\n",
    "    plt.close(fig)\n",
    "    return(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qq_data(df, category):\n",
    "    \"\"\"\n",
    "    Put all qq-plots in tabs.\n",
    "    \n",
    "    parameters:\n",
    "        df:         The dataframe with the data.\n",
    "        category:   List of names of columns of which the QQ plot will be created\n",
    "    \n",
    "    return:\n",
    "        qq:         Tabs with Panels with the qq-plots\n",
    "    \n",
    "    \"\"\"\n",
    "    qq = pn.Tabs()\n",
    "    for cat in category:\n",
    "        qq.append((f'{cat.split(\"_\")[0]}', pn.Row(Q_Q_Plot(df, cat, est='ML'),\n",
    "                                                  Q_Q_Plot(df, cat, est='robust'))))\n",
    "    return qq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure 9: Q-Q plot (ML) - ....      and   Q-Q plot (robust) - ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qq_plots = qq_data(pv_deceased_landuse_perc, cat_all)\n",
    "qq_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_normal_distribution(title, df, col, sub):\n",
    "    '''\n",
    "    Creates the histogram\n",
    "    \n",
    "    parameters:\n",
    "        title: The title for the plot\n",
    "        df:    The dataframe with the data.\n",
    "        col:   Name of a column of which the histogram plot is to be made\n",
    "    \n",
    "    return:\n",
    "        p:     The histogram\n",
    "    '''\n",
    "    mu_MM, sigma2_MM, sigma_MM, x, rv = cal_qq_and_histogram(df[col], True)\n",
    "    \n",
    "    p = figure(x_axis_label = title, y_axis_label='Probability')\n",
    "    p.add_layout(Title(text=f'For {sub}', text_font_size=\"8pt\", text_font_style=\"italic\"), 'above')\n",
    "    p.add_layout(Title(text=f'Histogram: {str(title)}', text_font_size=\"10pt\"), 'above')\n",
    "    \n",
    "    hist, edges = np.histogram(df[col], density=True, bins=df[col].nunique())\n",
    "    p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:],\n",
    "           fill_color=\"pink\", line_color=\"white\", alpha=1, legend_label = f\"{title} %\")    \n",
    "    p.line(x, rv, legend_label='Normal distribution', color='red')\n",
    "    \n",
    "    #Span of Average\n",
    "    col_average = df[col].mean()\n",
    "    span_average = Span(location=col_average,\n",
    "                                dimension='height', line_color='black',\n",
    "                                line_dash='dashed', line_width=1)\n",
    "    p.add_layout(span_average)\n",
    "    #Span of Median (robuust estimation)\n",
    "    col_median = df[col].median()\n",
    "    span_median = Span(location=col_median,\n",
    "                                dimension='height', line_color='blue',\n",
    "                                line_dash='dashed', line_width=1)\n",
    "    p.add_layout(span_median)\n",
    "\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.y_range.start = 0    \n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_plot_normal_distribution(df, col, cat_all):\n",
    "    '''\n",
    "    Put all histogram plots in tabs.\n",
    "    \n",
    "    parameters:\n",
    "        df:    The dataframe with the data.\n",
    "        col:   Name of a column of which the histogram plot is to be made\n",
    "        cat_all: List of names of columns of which the QQ plot will be created\n",
    "    \n",
    "    return:\n",
    "        p_end: Tabs with Panels with the histrograms\n",
    "    '''\n",
    "    big_tabs = []\n",
    "    for cat in cat_all:\n",
    "        p = make_plot_normal_distribution(cat.split('_')[0], df, cat, col)\n",
    "        big_tabs.append(Panel(child=p, title=str(cat.split('_')[0])))\n",
    "    p_end = Tabs(tabs=big_tabs)\n",
    "    return p_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure 10: Histogram: ..... (For RegioS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_region = data_plot_normal_distribution(pv_deceased_landuse_perc, 'RegioS', cat_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(normal_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure 11: Histogram: ..... (For Perioden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_per = data_plot_normal_distribution(pv_deceased_landuse_perc, 'Perioden', cat_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(normal_per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select\n",
    "For the following plots and the final conclusion I choose 1 column of the deceased and all total columns of land use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deceased_select = ['ZiektenVanAdemhalingsstelsel_4_percentage']\n",
    "land_select = [land for land in cat_land if \"Totaal\" in land]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_labels(p):\n",
    "    \"\"\"\n",
    "    rotate the labels on the x-axis and y-axis\n",
    "    \n",
    "    parameters:\n",
    "        p: plot\n",
    "    \n",
    "    return:\n",
    "        p: plot with rotated labels\n",
    "    \n",
    "    \"\"\"\n",
    "    for ax in p.axes.flatten():\n",
    "        # rotate x axis labels\n",
    "        ax.set_xlabel(ax.get_xlabel(), rotation = 90)\n",
    "        # rotate y axis labels\n",
    "        ax.set_ylabel(ax.get_ylabel(), rotation = 0)\n",
    "        # set y labels alignment\n",
    "        ax.yaxis.get_label().set_horizontalalignment('right')\n",
    "    return p\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplot\n",
    "* figure 12: Scatter plot for all columns - seaborn\n",
    "* figure 13: Scatter plot for selected columns - seaborn\n",
    "* figure 14: '..Year..': ('..land use column..') vs ('..deceased column..'). ('..year..' for different Regions)\n",
    "* figure 15: '..Region..': ('..land use column..') vs ('..deceased column..'). ('..Regio..' for different Periods)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure 12: Scatter plot for all columns - seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairplot = sns.pairplot(pv_deceased_landuse_perc[cat_all].dropna(how = 'any', axis = 0))\n",
    "all_pairplot = rotate_labels(all_pairplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure 13: Scatter plot for selected columns - seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_select = deceased_select + land_select\n",
    "select_pairplot = sns.pairplot(pv_deceased_landuse_perc[all_select].dropna(how = 'any', axis = 0))\n",
    "select_pairplot = rotate_labels(select_pairplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatterplot(df, source, title, sub_title, col1, col2, color, field):\n",
    "    '''\n",
    "    Makes scatter plots\n",
    "    \n",
    "    parameters:\n",
    "        df:      The dataframe with the data.\n",
    "        source:  The source (dataframe, data) of which the plot is to be made.\n",
    "        title:   The title for the scatterplot\n",
    "        sub_title: The sub title for the scatterplot\n",
    "        col1:    The name of the column on the x-as\n",
    "        col2:    The name of the column on the y-as\n",
    "        color:   The color palette\n",
    "        field:\n",
    "    \n",
    "    return:\n",
    "        p:       The scatterplot\n",
    "    '''\n",
    "    p = figure(x_axis_label = str(col1.split('_')[0] + ' percentage'), y_axis_label=str(col2.split('_')[0] + ' percentage'))\n",
    "    p.add_layout(Title(text=sub_title, text_font_size=\"8pt\", text_font_style=\"italic\"), 'above')\n",
    "    p.add_layout(Title(text=title, text_font_size=\"10pt\"), 'above')\n",
    "    list_field_values = list(set(df[field]))\n",
    "    # Sort so that the legend is sorted\n",
    "    list_field_values.sort()\n",
    "    r = p.scatter(col1, col2, fill_alpha=0.9, line_color=None, size=20, source=source, \n",
    "              color=factor_cmap(field, color[len(list_field_values)], list_field_values)\n",
    "             )\n",
    "    \n",
    "    #Site I've Used:: https://discourse.bokeh.org/t/representing-data-with-two-categories-by-both-color-and-marker-shape/4122/5\n",
    "    # we are going to add \"dummy\" renderers for the legends, restrict auto-ranging\n",
    "    # to only the \"real\" renderer above\n",
    "    p.x_range.renderers = [r]\n",
    "    p.y_range.renderers = [r]\n",
    "    # create an invisible renderer to drive color legend\n",
    "    rc = p.scatter(x=0, y=0, color=color[len(list_field_values)])\n",
    "    rc.visible = False\n",
    "    # add a color legend with explicit index, set labels to fit your need\n",
    "    legend = Legend(items=[\n",
    "                        LegendItem(label=list_field_values[i], renderers=[rc], index=i) for i, c in enumerate(color[len(list_field_values)])\n",
    "                    ], location=\"top_center\")\n",
    "    p.add_layout(legend) \n",
    "    \n",
    "    # Legend\n",
    "    new_legend = p.legend[0]\n",
    "    p.add_layout(new_legend, 'right')\n",
    "    p.legend.orientation = \"vertical\"\n",
    "      \n",
    "    # Hover\n",
    "    tips = [\n",
    "        (\"Periods\", \"@Perioden\"),\n",
    "        ('Region', '@RegioS')\n",
    "    ]\n",
    "    for name in [col1, col2]:\n",
    "        new_name = name.split('_')[0]\n",
    "        tips.append( (new_name, f'@{name} %') )\n",
    "        \n",
    "    p.add_tools(HoverTool( tooltips = tips\n",
    "                            ))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_scatterplot(df, col1, col2, cat_1, cat_2, color):\n",
    "    '''\n",
    "    Ensures that the data is good for making a scatter plot.\n",
    "    Put the scatter plots in tabs.\n",
    "    \n",
    "    parameters:\n",
    "        df:      The dataframe with the data.\n",
    "        col1:    'RegioS'/'Perioden': Different plots are created for all different values in col1 (column of df).\n",
    "        col2:    'RegioS'/'Perioden': The colors of these plots (circles) are based on col 2 (column from df)\n",
    "        cat_1:   List of column names (x-as)\n",
    "        cat_2:   List of column names (y-as)\n",
    "        color:   The color palette\n",
    "    \n",
    "    return:\n",
    "        p_end:   Tabs with Panels with the scatterplots\n",
    "    '''\n",
    "    set_col1 = set(df[col1])\n",
    "    big_tabs = []\n",
    "    for name in set_col1:\n",
    "        # Filter the data\n",
    "        filter_df = df[df[col1] == name].copy()\n",
    "        filter_df = filter_df.sort_values(col2)\n",
    "        filter_df['Perioden'] = filter_df['Perioden'].astype(str)        \n",
    "        source_df = ColumnDataSource(data=filter_df)\n",
    "        tabs = []\n",
    "        for cat in cat_1:\n",
    "            tab = []\n",
    "            for cat_disease in cat_2:\n",
    "                title = f'{name}: {cat.split(\"_\")[0]} vs {cat_disease.split(\"_\")[0]}'\n",
    "                sub_title = f'({name} for different {col2})'\n",
    "                p = scatterplot(filter_df, source_df, title, sub_title, cat, cat_disease, color, col2)\n",
    "                tab.append(Panel(child=p, title=cat_disease.split('_')[0]))\n",
    "            p_childchild = Tabs(tabs=tab)\n",
    "            tabs.append(Panel(child=p_childchild, title=cat.split('_')[0]))\n",
    "        p_child = Tabs(tabs=tabs)\n",
    "        big_tabs.append(Panel(child=p_child, title=str(name)))\n",
    "    p_end = Tabs(tabs=big_tabs)\n",
    "    return p_end   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_region = data_scatterplot(pv_deceased_landuse_perc, 'RegioS','Perioden', land_select, deceased_select, Set3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(scatter_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_periods = data_scatterplot(pv_deceased_landuse_perc, 'Perioden','RegioS', land_select, deceased_select, Set3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(scatter_periods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map\n",
    "* figure 16: ('..land use column..') in '..Year_intrest..'     - ('..deceased column..') in '..Year_intrest..'\n",
    "<br>\n",
    "<br>\n",
    "For this plot I have chosen to depict the last year (2015).\n",
    "If you are interested in another year you can adjust year_intrest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_grens_data(path):\n",
    "    '''\n",
    "    The boundary data is read here and certain values are added in a data frame\n",
    "    \n",
    "    parameters:\n",
    "        path:  path to the boundary data\n",
    "    \n",
    "    return:\n",
    "        df:           The dataframe with the data out of the boundary data.\n",
    "        geojson_data: A dictionary with the boundary data\n",
    "        \n",
    "    \n",
    "    '''\n",
    "    with open(path) as json_data:\n",
    "        geojson_data = json.load(json_data)\n",
    "    \n",
    "    #This data frame is created because it makes it easier to view the data compared to geojson_data.\n",
    "    df = pd.DataFrame()\n",
    "    for i in geojson_data['features']: \n",
    "        df = df.append({'Prov_naam': i['properties']['name'], 'coordinates': i['geometry']['coordinates'][0]}, ignore_index=True)\n",
    "    return df, geojson_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.webuildinternet.com/articles/2015-07-19-geojson-data-of-the-netherlands/provinces.geojson\n",
    "df_border_pv, geojson_data = read_grens_data(config['path_provinces']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_map(df, year):\n",
    "    \"\"\"\n",
    "    Filters the data frame by year.\n",
    "    And changed some values in the dataframe\n",
    "    \n",
    "    \n",
    "    parameters:\n",
    "        df:              The dataframe with the data.\n",
    "        year:            The year to filter (year of interest)\n",
    "    \n",
    "    returns:\n",
    "        df:              The data frame, but now with an extra column 'Prov'\n",
    "        df_year_intrest: filtered data frame (by year)\n",
    "        year_intrest:    year of interest as string\n",
    "    \n",
    "    \n",
    "    Doctest:\n",
    "    >>> filter_data_map(pd.DataFrame({\"RegioS\": ['Groningen (PV)' ,'Gelderland (PV)', 'Friesland (FryslÃ¢n) (PV)', 'Zuid-Holland (PV)', 'Friesland (PV)', 'Utrecht (PV)'], \"Perioden\": [2013 ,2020, 2013, 2012, 2013, 2000], \"test\": [2 ,2, 8, 24, 66, 9]}), 2013)\n",
    "    (                      RegioS  Perioden  test          Prov\n",
    "    0             Groningen (PV)      2013     2     Groningen\n",
    "    1            Gelderland (PV)      2020     2    Gelderland\n",
    "    2  Friesland (FryslÃ¢n) (PV)      2013     8     Friesland\n",
    "    3          Zuid-Holland (PV)      2012    24  Zuid-Holland\n",
    "    4             Friesland (PV)      2013    66     Friesland\n",
    "    5               Utrecht (PV)      2000     9       Utrecht, Empty DataFrame\n",
    "    Columns: [RegioS, Perioden, test, Prov]\n",
    "    Index: [], '2013')\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    # Filter data on 2015 years only. Chosen to only color the year 2015 on the map.\n",
    "    # Add a new column Prov which is the same as the names in geojson_data\n",
    "    year_intrest = str(year)\n",
    "    df['Prov'] = df['RegioS'].str.split(' ').str[0]\n",
    "    df_year_intrest = df[df['Perioden'] == year_intrest].copy()\n",
    "    df_year_intrest['Prov'] = df_year_intrest['Prov'].replace('Friesland','Friesland (FryslÃ¢n)')\n",
    "    return df, df_year_intrest, year_intrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_deceased_landuse_perc, pv_deceased_landuse_perc_year_intrest, year_intrest = filter_data_map(pv_deceased_landuse_perc, 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the names are the same\n",
    "print(df_border_pv['Prov_naam'])\n",
    "print(pv_deceased_landuse_perc_year_intrest['Prov'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_info_geojson(geojson_data, cat_all, df):\n",
    "    \"\"\"\n",
    "    New values are added in geojson_data.\n",
    "    The column names with their corresponding values, per province.\n",
    "    \n",
    "    parameters:\n",
    "        geojson_data: A dictionary with the boundary data\n",
    "        cat_all:      List of names of columns.\n",
    "        df:           The dataframe with the data.\n",
    "        \n",
    "    return:\n",
    "        geojson_data: A dictionary with the boundary data, and new added value\n",
    "    \n",
    "    \n",
    "    Doctest:\n",
    "    >>> add_info_geojson({\"type\": \"FeatureCollection\", \"features\": [ { \"type\": \"Feature\", \"geometry\": { \"type\": \"Point\", \"coordinates\": [102.0, 0.5] }, \"properties\": { \"name\": \"test1\", \"prop0\": \"value0\" } }, { \"type\": \"Feature\", \"geometry\": { \"type\": \"LineString\", \"coordinates\": [ [102.0, 0.0], [103.0, 1.0], [104.0, 0.0], [105.0, 1.0] ] }, \"properties\": { \"name\": \"test2\", \"prop0\": \"value0\", \"prop1\": 0.0 } }, { \"type\": \"Feature\", \"geometry\": { \"type\": \"Polygon\", \"coordinates\": [ [ [100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0], [100.0, 0.0] ] ] }, \"properties\": { \"name\": \"test3\", \"prop0\": \"value0\", \"prop1\": { \"this\": \"that\" } } } ] }, ['name1', 'name2'], pd.DataFrame({\"name1\": [1 ,4, 4, 8, 6], \"name2\": [8, 24, 3, 440, -90], \"name3\": [1, 2, 3, 4 , 5,], \"Prov\": ['test4', 'test1', 'test2', 'test5', 'test3']}))\n",
    "    {'type': 'FeatureCollection', 'features': [{'type': 'Feature', 'geometry': {'type': 'Point', 'coordinates': [102.0, 0.5]}, 'properties': {'name': 'test1', 'prop0': 'value0', 'name1': 4, 'name2': 24}}, {'type': 'Feature', 'geometry': {'type': 'LineString', 'coordinates': [[102.0, 0.0], [103.0, 1.0], [104.0, 0.0], [105.0, 1.0]]}, 'properties': {'name': 'test2', 'prop0': 'value0', 'prop1': 0.0, 'name1': 4, 'name2': 3}}, {'type': 'Feature', 'geometry': {'type': 'Polygon', 'coordinates': [[[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0], [100.0, 0.0]]]}, 'properties': {'name': 'test3', 'prop0': 'value0', 'prop1': {'this': 'that'}, 'name1': 6, 'name2': -90}}]}\n",
    "    \n",
    "    \"\"\"\n",
    "    # Add the percentages of all categories (landuse and deceased) per province geojson_data.\n",
    "    # This is to get the numbers when you hoover over a province.\n",
    "    for cat in cat_all:\n",
    "        for i in geojson_data['features']:\n",
    "            prov_name = i['properties']['name']\n",
    "            i['properties'][cat] = df[df['Prov'] == prov_name][cat].values[0]\n",
    "    return geojson_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_data = add_info_geojson(geojson_data, cat_all, pv_deceased_landuse_perc_year_intrest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_map(df, geojson_data, category, year_intrest):\n",
    "    \"\"\"\n",
    "    Creates a folder per column (category) and puts it in a list\n",
    "    \n",
    "    parameters:\n",
    "        df:            The dataframe with the data.\n",
    "        geojson_data:  A dictionary with the boundary data\n",
    "        category:      List of names of columns.\n",
    "        year_intrest:  year of interest as string\n",
    "        \n",
    "    return:\n",
    "        m_list:        list with all created maps\n",
    "    \n",
    "    \"\"\"\n",
    "    m_list = []\n",
    "    for cat in category:\n",
    "        # The location is the coordinates of Utrecht (this city is roughly in the middle of the Netherlands)\n",
    "        m = folium.Map(location=[52.0907374, 5.1214201], zoom_start=6, tiles=\"openstreetmap\")\n",
    "        # Adds colors to the map\n",
    "        choropleth = folium.Choropleth(\n",
    "            geo_data=geojson_data,\n",
    "            name=cat,\n",
    "            data=df,\n",
    "            columns=[\"Prov\", cat],\n",
    "            key_on=\"feature.properties.name\",\n",
    "            fill_color=\"BuPu\",\n",
    "            fill_opacity=0.7,\n",
    "            line_opacity=0.2,\n",
    "            legend_name=f'{cat.split(\"_\")[0]} Rate (%)',\n",
    "            highlight=True,\n",
    "            show=False,\n",
    "        ).add_to(m)\n",
    "        # Adds data when hovering around the map\n",
    "        choropleth.geojson.add_child(\n",
    "            folium.features.GeoJsonTooltip(fields=['name', cat],\n",
    "                                           aliases=['province:', f'value %:'],labels=True)\n",
    "        )\n",
    "        \n",
    "        # Adds title to the map\n",
    "        title_html = '''\n",
    "                     <h3 align=\"center\" style=\"font-size:12px\"><b>{}</b></h3>\n",
    "                     '''.format(f'{cat.split(\"_\")[0]} in {year_intrest}')\n",
    "        m.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "        m_list.append(m)\n",
    "    return m_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_land = data_map(pv_deceased_landuse_perc_year_intrest, geojson_data, land_select, year_intrest)\n",
    "m_deceased = data_map(pv_deceased_landuse_perc_year_intrest, geojson_data, deceased_select, year_intrest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tabs_maps(m_land, m_deceased, select_dec, select_land):\n",
    "    \"\"\"\n",
    "    Creates tabs and inserts two maps per tab.\n",
    "    \n",
    "    parameters:\n",
    "        m_land:      List with maps for land use\n",
    "        m_deceased:  List with maps for deceased\n",
    "        select_dec:  List of names of columns (deceased)\n",
    "        select_land: List of names of columns (land use)\n",
    "        \n",
    "    return:\n",
    "        the_maps:    Tabs with the map for land use and map for deceased.\n",
    "    \n",
    "    \"\"\"\n",
    "    the_maps = pn.Tabs()\n",
    "    for index_land, land in enumerate(m_land):\n",
    "        tabs = pn.Tabs()\n",
    "        for index_deceased, deceased in enumerate(m_deceased):\n",
    "            tabs.append((f'{select_dec[index_deceased].split(\"_\")[0]}',pn.Row(land,deceased))) #height=500, width=1000\n",
    "        the_maps.append((f'{select_land[index_land].split(\"_\")[0]}', tabs))\n",
    "    return the_maps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure 16: ('..land use column..') in '..Year_intrest..' - ('..deceased column..') in '..Year_intrest..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_maps = make_tabs_maps(m_land, m_deceased, deceased_select, land_select)\n",
    "the_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Least Squares (OLS)\n",
    "* figure 17: OLS results\n",
    "    * Summary results normal\n",
    "    * p-value sig normal (sig = significant)\n",
    "    * summary results robust\n",
    "    * p-value sig robust (sig = significant)\n",
    "    * seaborn OLS\n",
    "    * bokeh OLS\n",
    "* figure 18: seaborn lmplot - Perioden\n",
    "* figure 19: seaborn lmplot - RegioS\n",
    "* figure 20: seaborn jointplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_results(results, land):\n",
    "    '''\n",
    "    Creates a dictionary of a number of results.\n",
    "    And checks whether the p-value is significant.\n",
    "    \n",
    "    parameters:\n",
    "        results:  Results of OLS\n",
    "        land:     Column name (land use)\n",
    "        \n",
    "    return:\n",
    "        dict_res: Dictionary with a number of results\n",
    "    \n",
    "    '''\n",
    "    alpha = 0.05\n",
    "    dict_res = {f\"const params\": results.params[0],\n",
    "                f\"const p-value\": results.pvalues[0],\n",
    "                f'const p-value significant': results.pvalues[0]<=alpha,\n",
    "                f'{land} params': results.params[1],\n",
    "                f'{land} p-value': results.pvalues[1],\n",
    "                f'{land} p-value significant': results.pvalues[1]<=alpha,\n",
    "               }\n",
    "    return dict_res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinary_least_squares(df, land, deceased):\n",
    "    '''\n",
    "    Performs OLS test.\n",
    "    \n",
    "    paramters:\n",
    "        df:        The dataframe with the data.\n",
    "        land:      Column name (land use)\n",
    "        deceased:  Column name (deceased)\n",
    "        \n",
    "    returns:\n",
    "        model:           model of OLS\n",
    "        results_normal:  Results of OLS (normal)\n",
    "        results_robust:  Results of OLS (robust)\n",
    "        dict_res_normal: Dictionary with a number of results (normal)\n",
    "        dict_res_robust: Dictionary with a number of results (robust)\n",
    "    \n",
    "    '''\n",
    "    # dependent variable\n",
    "    Y = df[deceased]\n",
    "    # independent variable\n",
    "    X = df[land]\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(Y, X)\n",
    "    # Normal\n",
    "    results_normal = model.fit()\n",
    "    # Makes the data robust\n",
    "    results_robust = results_normal.get_robustcov_results(cov_type='HC1')\n",
    "    dict_res_normal = dict_results(results_normal, land)\n",
    "    dict_res_robust = dict_results(results_robust, land)    \n",
    "    return model, results_normal, results_robust, dict_res_normal, dict_res_robust   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS_seaborn(x, y, df): \n",
    "    '''\n",
    "    Plot data and a linear regression model fit, seaborn.\n",
    "    \n",
    "    parameters:\n",
    "        x:   The name of the column on the x-as\n",
    "        y:   The name of the column on the y-as\n",
    "        df:  The dataframe with the data.\n",
    "        \n",
    "    return:\n",
    "        p:   plot\n",
    "    \n",
    "    '''\n",
    "    plt.ioff\n",
    "    p = plt.figure(figsize=(8, 6))\n",
    "    sns.regplot(x=x, y=y, data=df)\n",
    "    plt.title(f'linear regression model: {x.split(\"_\")[0]}-{y.split(\"_\")[0]}')\n",
    "    plt.close(p)\n",
    "    return p   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS_bokeh(df, land, deceased,normal, robust):\n",
    "    '''\n",
    "    Creates an OLS regression plot in bokeh\n",
    "    \n",
    "    parameters:\n",
    "        df:        The dataframe with the data.\n",
    "        land:      The name of the column on the x-as\n",
    "        deceased:  The name of the column on the y-as\n",
    "        normal:    Results of OLS (normal)\n",
    "        robust:    Results of OLS (Robust)\n",
    "    \n",
    "    return:\n",
    "        pig:       plot\n",
    "    \n",
    "    '''\n",
    "    # Make new x and y (normal)\n",
    "    x_normal = np.linspace(0,30,300)\n",
    "    y_normal = normal.params[0] + normal.params[1] * x_normal\n",
    "    # Make new x and y (robust)\n",
    "    x_robust = np.linspace(0,30,300)\n",
    "    y_robust = robust.params[0] + robust.params[1] * x_robust\n",
    "    \n",
    "    source = ColumnDataSource(df)\n",
    "    pig = figure(x_range=(min(df[land])*1.1, max(df[land])*1.1), y_range=(min(df[deceased])*1.1, max(df[deceased])*1.1))\n",
    "    pig.circle(x=land, y=deceased, source=source)\n",
    "    pig.line(x_normal, y_normal, color='red', legend_label='normal')\n",
    "    pig.line(x_robust, y_robust, color='green', legend_label='robust')\n",
    "    pig.add_layout(Title(text='bokeh', text_font_size=\"8pt\", text_font_style=\"italic\"), 'above')\n",
    "    pig.add_layout(Title(text=f'OLS: {land.split(\"_\")[0]}-{deceased.split(\"_\")[0]}', text_font_size=\"10pt\"), 'above')\n",
    "     \n",
    "    return pig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tabs_OLS(df, deceased_select, land_select):\n",
    "    \"\"\"\n",
    "    Put the results and plots of the OLS in tabs\n",
    "    \n",
    "    parameters:\n",
    "        df:              The dataframe with the data.\n",
    "        deceased_select: Column names (deceased)\n",
    "        land_select:     Column names (land use)\n",
    "        \n",
    "    return:\n",
    "        deceased_tab:    Tabs with results / plots OLS\n",
    "    \"\"\"\n",
    "    deceased_tab = pn.Tabs()\n",
    "    for deceased in deceased_select:\n",
    "        land_tab = pn.Tabs()\n",
    "        for land in land_select:\n",
    "            model, results_normal, results_robust, dict_res_normal, dict_res_robust = ordinary_least_squares(df, land, deceased)\n",
    "            bokeh_ols = OLS_bokeh(df, land, deceased, results_normal, results_robust)\n",
    "            seaborn_ols = OLS_seaborn(land, deceased, df)\n",
    "            tabs = pn.Tabs(('summary results normaal', results_normal.summary()),\n",
    "                          ('p-value sig normal', dict_res_normal),\n",
    "                          ('summary results robust', results_robust.summary()),\n",
    "                          ('p-value sig normal', dict_res_robust),\n",
    "                          ('seaborn OLS',seaborn_ols),\n",
    "                          ('bokeh OLS',bokeh_ols))            \n",
    "            land_tab.append((f'{land.split(\"_\")[0]}', tabs))\n",
    "        deceased_tab.append((f'{deceased.split(\"_\")[0]}', land_tab))\n",
    "    return deceased_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure 17: OLS results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLS_tab = create_tabs_OLS(pv_deceased_landuse_perc, deceased_select, land_select)\n",
    "OLS_tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few nice plots.\n",
    "These are only done with x = 'TotaalBosEnOpenNatuurlijkTerrein_28_percentage', and\n",
    "             y = 'DiseasesOfRespiratory_4_percentage'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure 18: seaborn lmplot - Perioden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot data and regression model fits across a FacetGrid.\n",
    "periods_data = sns.lmplot(x='TotaalBosEnOpenNatuurlijkTerrein_28_percentage', \n",
    "            y='ZiektenVanAdemhalingsstelsel_4_percentage',\n",
    "           hue=\"Perioden\", col='Perioden', col_wrap=4, height=3,\n",
    "           data=pv_deceased_landuse_perc) \n",
    "periods_data = rotate_labels(periods_data)\n",
    "periods_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure 19: seaborn lmplot - RegioS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data and regression model fits across a FacetGrid.\n",
    "region_data = sns.lmplot(x='TotaalBosEnOpenNatuurlijkTerrein_28_percentage', \n",
    "                        y='ZiektenVanAdemhalingsstelsel_4_percentage',\n",
    "                       hue=\"RegioS\", col='RegioS', col_wrap=3, height=3,\n",
    "                       data=pv_deceased_landuse_perc) \n",
    "region_data = rotate_labels(region_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### figure 20: seaborn jointplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a plot of two variables with bivariate and univariate graphs.\n",
    "sns.jointplot(x='TotaalBosEnOpenNatuurlijkTerrein_28_percentage', \n",
    "            y='ZiektenVanAdemhalingsstelsel_4_percentage', \n",
    "            data=pv_deceased_landuse_perc, kind=\"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doctest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs all doctest\n",
    "if __name__ == \"__main__\":\n",
    "    doctest.testmod(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
